{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99324db5-e778-4121-8416-bb436b6982a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (25.0.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "Writing to /root/.config/pip/pip.conf\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: optimum[neuronx] in /opt/conda/lib/python3.10/site-packages (1.23.3)\n",
      "Collecting optimum[neuronx]\n",
      "  Using cached optimum-1.24.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: transformers>=4.29 in /opt/conda/lib/python3.10/site-packages (from optimum[neuronx]) (4.48.3)\n",
      "Requirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.10/site-packages (from optimum[neuronx]) (2.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from optimum[neuronx]) (24.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optimum[neuronx]) (1.25.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from optimum[neuronx]) (0.29.2)\n",
      "Requirement already satisfied: optimum-neuron>=0.0.20 in /opt/conda/lib/python3.10/site-packages (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.0.28)\n",
      "Collecting transformers>=4.29 (from optimum[neuronx])\n",
      "  Using cached transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[neuronx]) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[neuronx]) (2024.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[neuronx]) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[neuronx]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[neuronx]) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[neuronx]) (4.12.2)\n",
      "INFO: pip is looking at multiple versions of optimum-neuron to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting optimum-neuron>=0.0.20 (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx])\n",
      "  Using cached optimum_neuron-0.0.27-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached optimum_neuron-0.0.26-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached optimum_neuron-0.0.25-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached optimum_neuron-0.0.24-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting transformers>=4.29 (from optimum[neuronx])\n",
      "  Using cached transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: accelerate==0.29.2 in /opt/conda/lib/python3.10/site-packages (from optimum-neuron>=0.0.20->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.29.2)\n",
      "Collecting optimum-neuron>=0.0.20 (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx])\n",
      "  Using cached optimum_neuron-0.0.23-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached optimum_neuron-0.0.22-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting transformers>=4.29 (from optimum[neuronx])\n",
      "  Using cached transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "Collecting accelerate==0.23.0 (from optimum-neuron>=0.0.20->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx])\n",
      "  Using cached accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting optimum-neuron>=0.0.20 (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx])\n",
      "  Using cached optimum_neuron-0.0.21-py3-none-any.whl.metadata (14 kB)\n",
      "INFO: pip is still looking at multiple versions of optimum-neuron to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached optimum_neuron-0.0.20-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from optimum[neuronx]) (15.0.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum[neuronx]) (1.13.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum[neuronx]) (2.19.1)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting optimum[neuronx]\n",
      "  Using cached optimum-1.23.3-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached optimum-1.23.2-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached optimum-1.23.1-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached optimum-1.23.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached optimum-1.22.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting transformers<4.45.0,>=4.29 (from transformers[sentencepiece]<4.45.0,>=4.29->optimum[neuronx])\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting optimum[neuronx]\n",
      "  Using cached optimum-1.21.4-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers<4.44.0,>=4.29.0 (from transformers[sentencepiece]<4.44.0,>=4.29.0->optimum[neuronx])\n",
      "  Using cached transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting optimum[neuronx]\n",
      "  Using cached optimum-1.21.3-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached optimum-1.21.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting transformers<4.43.0,>=4.26.0 (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum[neuronx])\n",
      "  Using cached transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting optimum[neuronx]\n",
      "  Using cached optimum-1.21.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached optimum-1.21.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached optimum-1.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: protobuf<4 in /opt/conda/lib/python3.10/site-packages (from optimum-neuron>=0.0.20->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (3.20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.29->optimum[neuronx]) (2024.11.6)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers>=4.29->optimum[neuronx])\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.29->optimum[neuronx]) (0.4.5)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.29.2->optimum-neuron>=0.0.20->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (5.9.5)\n",
      "INFO: pip is looking at multiple versions of optimum-neuron[neuronx] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.45.1)\n",
      "Collecting neuronx-cc==2.14.227.0 (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx])\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/neuronx-cc/neuronx_cc-2.14.227.0%2B2d4f85be-cp310-cp310-linux_x86_64.whl (392.3 MB)\n",
      "Collecting torch-neuronx==2.1.2.2.2.0 (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx])\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuronx/torch_neuronx-2.1.2.2.2.0-py3-none-any.whl (2.5 MB)\n",
      "Collecting transformers-neuronx==0.11.351 (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx])\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/transformers-neuronx/transformers_neuronx-0.11.351-py3-none-any.whl (240 kB)\n",
      "Collecting torch>=1.11 (from optimum[neuronx])\n",
      "  Using cached torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: torchvision==0.16.* in /opt/conda/lib/python3.10/site-packages (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.16.2)\n",
      "Collecting neuronx-distributed==0.8.0 (from optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx])\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/neuronx-distributed/neuronx_distributed-0.8.0-py3-none-linux_x86_64.whl (172 kB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum[neuronx]) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum[neuronx]) (3.1.4)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11->optimum[neuronx])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11->optimum[neuronx])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11->optimum[neuronx])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11->optimum[neuronx])\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11->optimum[neuronx])\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11->optimum[neuronx])\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11->optimum[neuronx])\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11->optimum[neuronx])\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11->optimum[neuronx])\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch>=1.11->optimum[neuronx])\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11->optimum[neuronx])\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.1.0 (from torch>=1.11->optimum[neuronx])\n",
      "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: scipy<=1.11.2 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc==2.14.227.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.10.1)\n",
      "Requirement already satisfied: python-daemon>=2.2.4 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc==2.14.227.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (3.1.2)\n",
      "Requirement already satisfied: requests-unixsocket>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc==2.14.227.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.3.0)\n",
      "Requirement already satisfied: islpy~=2023.1 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc==2.14.227.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2023.2.5)\n",
      "Collecting protobuf<4 (from optimum-neuron>=0.0.20->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx])\n",
      "  Using cached protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
      "Requirement already satisfied: pgzip>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc==2.14.227.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.3.5)\n",
      "Requirement already satisfied: ec2-metadata~=2.10 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc==2.14.227.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.14.0)\n",
      "Requirement already satisfied: torch-xla in /opt/conda/lib/python3.10/site-packages (from neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.5.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->optimum[neuronx]) (12.4.127)\n",
      "Collecting torch-xla (from neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx])\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-xla/torch_xla-2.1.3-cp310-cp310-manylinux_2_28_x86_64.whl (81.1 MB)\n",
      "Requirement already satisfied: libneuronxla<3.0,>2.0.965 in /opt/conda/lib/python3.10/site-packages (from torch-neuronx==2.1.2.2.2.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.1.681.0)\n",
      "Requirement already satisfied: setuptools<=69.5.1 in /opt/conda/lib/python3.10/site-packages (from torch-neuronx==2.1.2.2.2.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (69.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.*->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (11.0.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.1.0)\n",
      "Requirement already satisfied: cloud-tpu-client>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.10)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.42.0,>=4.26.0->optimum[neuronx]) (0.2.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->optimum[neuronx]) (10.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[neuronx]) (19.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[neuronx]) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[neuronx]) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[neuronx]) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[neuronx]) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[neuronx]) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum[neuronx]) (3.11.13)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum[neuronx]) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neuronx]) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neuronx]) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neuronx]) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neuronx]) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neuronx]) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neuronx]) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neuronx]) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neuronx]) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum[neuronx]) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum[neuronx]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum[neuronx]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum[neuronx]) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum[neuronx]) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum[neuronx]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum[neuronx]) (2024.2)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from libneuronxla<3.0,>2.0.965->torch-neuronx==2.1.2.2.2.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.28.60)\n",
      "Requirement already satisfied: botocore in /opt/conda/lib/python3.10/site-packages (from libneuronxla<3.0,>2.0.965->torch-neuronx==2.1.2.2.2.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.31.85)\n",
      "Requirement already satisfied: lockfile>=0.10 in /opt/conda/lib/python3.10/site-packages (from python-daemon>=2.2.4->neuronx-cc==2.14.227.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum[neuronx]) (1.16.0)\n",
      "Requirement already satisfied: google-api-python-client==1.8.0 in /opt/conda/lib/python3.10/site-packages (from cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.8.0)\n",
      "Requirement already satisfied: oauth2client in /opt/conda/lib/python3.10/site-packages (from cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (4.1.3)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.22.0)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (2.38.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.2.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.34.1)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (3.0.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->libneuronxla<3.0,>2.0.965->torch-neuronx==2.1.2.2.2.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from boto3->libneuronxla<3.0,>2.0.965->torch-neuronx==2.1.2.2.2.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.7.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /opt/conda/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (0.4.1)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (4.7.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (1.63.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (5.5.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1dev,>=0.9.2->google-api-python-client==1.8.0->cloud-tpu-client>=0.10.0->torch-xla->neuronx-distributed==0.8.0->optimum-neuron[neuronx]>=0.0.20; extra == \"neuronx\"->optimum[neuronx]) (3.2.1)\n",
      "Using cached optimum_neuron-0.0.24-py3-none-any.whl (345 kB)\n",
      "Using cached transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "Using cached optimum-1.20.0-py3-none-any.whl (418 kB)\n",
      "Using cached torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Using cached protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "Installing collected packages: triton, protobuf, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, tokenizers, neuronx-cc, transformers, torch-xla, optimum, torch-neuronx, optimum-neuron, transformers-neuronx, neuronx-distributed\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
      "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
      "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
      "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
      "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1\n",
      "    Uninstalling torch-2.5.1:\n",
      "      Successfully uninstalled torch-2.5.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.0\n",
      "    Uninstalling tokenizers-0.21.0:\n",
      "      Successfully uninstalled tokenizers-0.21.0\n",
      "  Attempting uninstall: neuronx-cc\n",
      "    Found existing installation: neuronx-cc 2.16.372.0+4a9b2326\n",
      "    Uninstalling neuronx-cc-2.16.372.0+4a9b2326:\n",
      "      Successfully uninstalled neuronx-cc-2.16.372.0+4a9b2326\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.48.3\n",
      "    Uninstalling transformers-4.48.3:\n",
      "      Successfully uninstalled transformers-4.48.3\n",
      "  Attempting uninstall: torch-xla\n",
      "    Found existing installation: torch-xla 2.5.1\n",
      "    Uninstalling torch-xla-2.5.1:\n",
      "      Successfully uninstalled torch-xla-2.5.1\n",
      "  Attempting uninstall: optimum\n",
      "    Found existing installation: optimum 1.23.3\n",
      "    Uninstalling optimum-1.23.3:\n",
      "      Successfully uninstalled optimum-1.23.3\n",
      "  Attempting uninstall: torch-neuronx\n",
      "    Found existing installation: torch-neuronx 2.5.1.2.4.0\n",
      "    Uninstalling torch-neuronx-2.5.1.2.4.0:\n",
      "      Successfully uninstalled torch-neuronx-2.5.1.2.4.0\n",
      "  Attempting uninstall: optimum-neuron\n",
      "    Found existing installation: optimum-neuron 0.0.28\n",
      "    Uninstalling optimum-neuron-0.0.28:\n",
      "      Successfully uninstalled optimum-neuron-0.0.28\n",
      "  Attempting uninstall: transformers-neuronx\n",
      "    Found existing installation: transformers-neuronx 0.13.322\n",
      "    Uninstalling transformers-neuronx-0.13.322:\n",
      "      Successfully uninstalled transformers-neuronx-0.13.322\n",
      "  Attempting uninstall: neuronx-distributed\n",
      "    Found existing installation: neuronx-distributed 0.10.1\n",
      "    Uninstalling neuronx-distributed-0.10.1:\n",
      "      Successfully uninstalled neuronx-distributed-0.10.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "neuronx-distributed-inference 0.1.0 requires blobfile, which is not installed.\n",
      "neuronx-distributed-inference 0.1.0 requires transformers==4.45.*, but you have transformers 4.41.1 which is incompatible.\n",
      "vllm 0.1.dev2830+g22c56ee.neuron216 requires transformers>=4.45.0, but you have transformers 4.41.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed neuronx-cc-2.14.227.0+2d4f85be neuronx-distributed-0.8.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 optimum-1.20.0 optimum-neuron-0.0.24 protobuf-3.19.6 tokenizers-0.19.1 torch-2.1.2 torch-neuronx-2.1.2.2.2.0 torch-xla-2.1.3 transformers-4.41.1 transformers-neuronx-0.11.351 triton-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: optimum-neuron in /opt/conda/lib/python3.10/site-packages (0.0.24)\n",
      "Collecting optimum-neuron\n",
      "  Using cached optimum_neuron-0.0.28-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: neuronx-cc in /opt/conda/lib/python3.10/site-packages (2.14.227.0+2d4f85be)\n",
      "Collecting neuronx-cc\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/neuronx-cc/neuronx_cc-2.16.372.0%2B4a9b2326-cp310-cp310-linux_x86_64.whl (580.9 MB)\n",
      "Requirement already satisfied: transformers_neuronx in /opt/conda/lib/python3.10/site-packages (0.11.351)\n",
      "Collecting transformers_neuronx\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/transformers-neuronx/transformers_neuronx-0.13.380-py3-none-any.whl (305 kB)\n",
      "Requirement already satisfied: neuronx_distributed in /opt/conda/lib/python3.10/site-packages (0.8.0)\n",
      "Collecting neuronx_distributed\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/neuronx-distributed/neuronx_distributed-0.10.1-py3-none-linux_x86_64.whl (261 kB)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.1)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: torch-neuronx in /opt/conda/lib/python3.10/site-packages (2.1.2.2.2.0)\n",
      "Collecting torch-neuronx\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuronx/torch_neuronx-2.5.1.2.4.0-py3-none-any.whl (2.6 MB)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.2)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: diffusers in /opt/conda/lib/python3.10/site-packages (0.32.2)\n",
      "Requirement already satisfied: triton in /opt/conda/lib/python3.10/site-packages (2.1.0)\n",
      "Collecting triton\n",
      "  Using cached triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (3.19.6)\n",
      "Collecting protobuf\n",
      "  Using cached protobuf-6.30.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting optimum~=1.23.3 (from optimum-neuron)\n",
      "  Using cached optimum-1.23.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from optimum-neuron) (0.29.2)\n",
      "Requirement already satisfied: numpy<=1.25.2,>=1.22.2 in /opt/conda/lib/python3.10/site-packages (from optimum-neuron) (1.25.2)\n",
      "Collecting protobuf\n",
      "  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: networkx~=2.6 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc) (2.8.8)\n",
      "Requirement already satisfied: scipy<=1.11.2 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc) (1.10.1)\n",
      "Requirement already satisfied: python-daemon>=2.2.4 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc) (3.1.2)\n",
      "Requirement already satisfied: requests<2.32.0 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc) (2.31.0)\n",
      "Requirement already satisfied: requests-unixsocket>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc) (0.3.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc) (0.2.0)\n",
      "Requirement already satisfied: islpy~=2023.1 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc) (2023.2.5)\n",
      "Requirement already satisfied: pgzip>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc) (0.3.5)\n",
      "Requirement already satisfied: ec2-metadata~=2.10 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc) (2.14.0)\n",
      "Requirement already satisfied: tqdm>=4 in /opt/conda/lib/python3.10/site-packages (from neuronx-cc) (4.67.1)\n",
      "INFO: pip is looking at multiple versions of transformers-neuronx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting transformers_neuronx\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/transformers-neuronx/transformers_neuronx-0.13.322-py3-none-any.whl (305 kB)\n",
      "Requirement already satisfied: torch-xla in /opt/conda/lib/python3.10/site-packages (from neuronx_distributed) (2.1.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting torch>=1.10.0 (from accelerate)\n",
      "  Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torch-xla (from neuronx_distributed)\n",
      "  Using cached torch_xla-2.5.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: libneuronxla<2.2,>=2.1 in /opt/conda/lib/python3.10/site-packages (from torch-neuronx) (2.1.681.0)\n",
      "Requirement already satisfied: setuptools<=69.5.1 in /opt/conda/lib/python3.10/site-packages (from torch-neuronx) (69.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.10.0->accelerate)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.4.127)\n",
      "Collecting triton\n",
      "  Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torch-xla->neuronx_distributed) (2.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers) (8.6.1)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers) (11.0.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from libneuronxla<2.2,>=2.1->torch-neuronx) (1.28.60)\n",
      "Requirement already satisfied: botocore in /opt/conda/lib/python3.10/site-packages (from libneuronxla<2.2,>=2.1->torch-neuronx) (1.31.85)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from optimum~=1.23.3->optimum-neuron) (15.0.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum~=1.23.3->optimum-neuron) (2.19.1)\n",
      "Requirement already satisfied: lockfile>=0.10 in /opt/conda/lib/python3.10/site-packages (from python-daemon>=2.2.4->neuronx-cc) (0.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<2.32.0->neuronx-cc) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<2.32.0->neuronx-cc) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<2.32.0->neuronx-cc) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<2.32.0->neuronx-cc) (2024.12.14)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.21.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->libneuronxla<2.2,>=2.1->torch-neuronx) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from boto3->libneuronxla<2.2,>=2.1->torch-neuronx) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore->libneuronxla<2.2,>=2.1->torch-neuronx) (2.9.0.post0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->optimum~=1.23.3->optimum-neuron) (10.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum~=1.23.3->optimum-neuron) (19.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->optimum~=1.23.3->optimum-neuron) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum~=1.23.3->optimum-neuron) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum~=1.23.3->optimum-neuron) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum~=1.23.3->optimum-neuron) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum~=1.23.3->optimum-neuron) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum~=1.23.3->optimum-neuron) (3.11.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum~=1.23.3->optimum-neuron) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum~=1.23.3->optimum-neuron) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum~=1.23.3->optimum-neuron) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum~=1.23.3->optimum-neuron) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum~=1.23.3->optimum-neuron) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum~=1.23.3->optimum-neuron) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum~=1.23.3->optimum-neuron) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum~=1.23.3->optimum-neuron) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore->libneuronxla<2.2,>=2.1->torch-neuronx) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum~=1.23.3->optimum-neuron) (2024.2)\n",
      "Using cached optimum_neuron-0.0.28-py3-none-any.whl (393 kB)\n",
      "Using cached transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "Using cached torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "Using cached triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "Using cached torch_xla-2.5.1-cp310-cp310-manylinux_2_28_x86_64.whl (90.6 MB)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "Using cached optimum-1.23.3-py3-none-any.whl (424 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "Installing collected packages: triton, protobuf, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, torch-xla, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, tokenizers, neuronx-cc, transformers, torch-neuronx, optimum, transformers_neuronx, optimum-neuron, neuronx_distributed\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
      "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
      "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
      "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
      "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
      "  Attempting uninstall: torch-xla\n",
      "    Found existing installation: torch-xla 2.1.3\n",
      "    Uninstalling torch-xla-2.1.3:\n",
      "      Successfully uninstalled torch-xla-2.1.3\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
      "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
      "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.2\n",
      "    Uninstalling torch-2.1.2:\n",
      "      Successfully uninstalled torch-2.1.2\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: neuronx-cc\n",
      "    Found existing installation: neuronx-cc 2.14.227.0+2d4f85be\n",
      "    Uninstalling neuronx-cc-2.14.227.0+2d4f85be:\n",
      "      Successfully uninstalled neuronx-cc-2.14.227.0+2d4f85be\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.41.1\n",
      "    Uninstalling transformers-4.41.1:\n",
      "      Successfully uninstalled transformers-4.41.1\n",
      "  Attempting uninstall: torch-neuronx\n",
      "    Found existing installation: torch-neuronx 2.1.2.2.2.0\n",
      "    Uninstalling torch-neuronx-2.1.2.2.2.0:\n",
      "      Successfully uninstalled torch-neuronx-2.1.2.2.2.0\n",
      "  Attempting uninstall: optimum\n",
      "    Found existing installation: optimum 1.20.0\n",
      "    Uninstalling optimum-1.20.0:\n",
      "      Successfully uninstalled optimum-1.20.0\n",
      "  Attempting uninstall: transformers_neuronx\n",
      "    Found existing installation: transformers-neuronx 0.11.351\n",
      "    Uninstalling transformers-neuronx-0.11.351:\n",
      "      Successfully uninstalled transformers-neuronx-0.11.351\n",
      "  Attempting uninstall: optimum-neuron\n",
      "    Found existing installation: optimum-neuron 0.0.24\n",
      "    Uninstalling optimum-neuron-0.0.24:\n",
      "      Successfully uninstalled optimum-neuron-0.0.24\n",
      "  Attempting uninstall: neuronx_distributed\n",
      "    Found existing installation: neuronx-distributed 0.8.0\n",
      "    Uninstalling neuronx-distributed-0.8.0:\n",
      "      Successfully uninstalled neuronx-distributed-0.8.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "neuronx-distributed-inference 0.1.0 requires blobfile, which is not installed.\n",
      "neuronx-distributed-inference 0.1.0 requires transformers==4.45.*, but you have transformers 4.48.3 which is incompatible.\n",
      "torchvision 0.16.2 requires torch==2.1.2, but you have torch 2.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed neuronx-cc-2.16.372.0+4a9b2326 neuronx_distributed-0.10.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.4.127 optimum-1.23.3 optimum-neuron-0.0.28 protobuf-3.20.3 tokenizers-0.21.0 torch-2.5.1 torch-neuronx-2.5.1.2.4.0 torch-xla-2.5.1 transformers-4.48.3 transformers_neuronx-0.13.322 triton-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: faiss-cpu in /opt/conda/lib/python3.10/site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.25.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -riton (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip \\\n",
    "&& pip config set global.extra-index-url https://pip.repos.neuron.amazonaws.com \\\n",
    "&& pip install --upgrade optimum[neuronx] \\\n",
    "&& pip install --upgrade optimum-neuron neuronx-cc transformers_neuronx neuronx_distributed transformers torch-neuronx accelerate diffusers triton protobuf \\\n",
    "&& pip install faiss-cpu numpy scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f4ccdd1-9980-4f21-a21b-eaddb809e544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>User_id</th>\n",
       "      <th>review/helpfulness</th>\n",
       "      <th>review/score</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/summary</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1882931173</td>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>AVCGYZL8FQQTD</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940636800</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A30TK6U7DNS82R</td>\n",
       "      <td>10/10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A3UH4UZ4RSVO82</td>\n",
       "      <td>10/11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A2MVUWT453QH61</td>\n",
       "      <td>7/7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1090713600</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0826414346</td>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>A22X4XUPKF66MR</td>\n",
       "      <td>3/3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107993600</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id                           Title         User_id  \\\n",
       "0  1882931173  Its Only Art If Its Well Hung!   AVCGYZL8FQQTD   \n",
       "1  0826414346        Dr. Seuss: American Icon  A30TK6U7DNS82R   \n",
       "2  0826414346        Dr. Seuss: American Icon  A3UH4UZ4RSVO82   \n",
       "3  0826414346        Dr. Seuss: American Icon  A2MVUWT453QH61   \n",
       "4  0826414346        Dr. Seuss: American Icon  A22X4XUPKF66MR   \n",
       "\n",
       "  review/helpfulness  review/score  review/time  \\\n",
       "0                7/7           4.0    940636800   \n",
       "1              10/10           5.0   1095724800   \n",
       "2              10/11           5.0   1078790400   \n",
       "3                7/7           4.0   1090713600   \n",
       "4                3/3           4.0   1107993600   \n",
       "\n",
       "                                    review/summary  \\\n",
       "0           Nice collection of Julie Strain images   \n",
       "1                                Really Enjoyed It   \n",
       "2  Essential for every personal and Public Library   \n",
       "3  Phlip Nel gives silly Seuss a serious treatment   \n",
       "4                           Good academic overview   \n",
       "\n",
       "                                         review/text  \n",
       "0  This is only for Julie Strain fans. It's a col...  \n",
       "1  I don't care much for Dr. Seuss but after read...  \n",
       "2  If people become the books they read and if \"t...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews?resource=download\n",
    "import pandas as pd\n",
    "\n",
    "def load_amazon_books():\n",
    "    url = \"file:///home/ubuntu/Books_rating.csv\"\n",
    "    df = pd.read_csv(url,nrows=10000)\n",
    "    #df = pd.read_csv(url)\n",
    "    df = df[['Id', 'Title', 'User_id', 'review/helpfulness', 'review/score', 'review/time', 'review/summary', 'review/text']]\n",
    "    return df\n",
    "    \n",
    "books_df = load_amazon_books()\n",
    "books_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3fa2def-74c1-4cc7-a5cc-86af0cc1e612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 03-11 01:24:40 _custom_ops.py:18] Failed to import from vllm._C with ModuleNotFoundError(\"No module named 'vllm._C'\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "WARNING:root:MASTER_ADDR environment variable is not set, defaulting to localhost\n",
      "WARNING:root:Found libneuronpjrt.so. Setting PJRT_DEVICE=NEURON.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-11 01:24:45 config.py:901] Defaulting to use mp for distributed inference\n",
      "WARNING 03-11 01:24:45 config.py:376] Async output processing is only supported for CUDA or TPU. Disabling it for other platforms.\n",
      "INFO 03-11 01:24:45 llm_engine.py:226] Initializing an LLM engine (v0.1.dev2830+g22c56ee) with config: model='deepseek-ai/DeepSeek-R1-Distill-Llama-8B', speculative_config=None, tokenizer='deepseek-ai/DeepSeek-R1-Distill-Llama-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=512, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cpu, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=deepseek-ai/DeepSeek-R1-Distill-Llama-8B, use_v2_block_manager=False, num_scheduler_steps=1, multi_step_stream_outputs=False, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "WARNING 03-11 01:24:46 utils.py:761] Pin memory is not supported on Neuron.\n",
      "WARNING 03-11 01:24:46 neuron_model_runner.py:102] On-device sampling is turned on in Neuron by default, only top_k, top_p, and temperature are current supported sampling parameters. To turn off the on-device sampling, please set the environment variable NEURON_ON_DEVICE_SAMPLING_DISABLED=1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/libneuronxla/neuron_cc_wrapper.py:196: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.\n",
      "  warnings.warn(SyntaxWarning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-11 01:25:07.000298:  92076  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.16.372.0+4a9b2326/MODULE_0b0de4d2c192c0c83660+613edded/model.neff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/libneuronxla/neuron_cc_wrapper.py:196: SyntaxWarning: str format compiler_flags is discouraged as its handling involves repeated joining and splitting, which can easily make mistakes if something is quoted or escaped. Use list[str] instead. Refer to documentation of the Python subprocess module for details.\n",
      "  warnings.warn(SyntaxWarning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-11 01:25:07.000354:  92077  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.16.372.0+4a9b2326/MODULE_35c6e080f021e405f235+613edded/model.neff\n",
      "2025-Mar-11 01:25:07.0763 91338:92060 [0] net_plugin.cc:70 CCOM WARN NET/Plugin: Error: libnccom-net.so load failed. libfabric.so.1: cannot open shared object file: No such file or directory. Please make sure to install the latest version of libfabric from https://efa-installer.amazonaws.com/aws-efa-installer-latest.tar.gz.\n"
     ]
    }
   ],
   "source": [
    "## Step 3: Deploy vLLM on Trainium (NxD) with Config YAML for main model\n",
    "from vllm import LLM, SamplingParams\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "os.environ[\"NEURON_RT_VISIBLE_CORES\"] = \"0-1\"\n",
    "\n",
    "# model\n",
    "model_vllm_config_yaml = \"\"\"\n",
    "model: \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "tensor_parallel_size: 2\n",
    "max_num_seqs: 1\n",
    "max_model_len: 512\n",
    "override_neuron_config: {}\n",
    "device: \"neuron\"\n",
    "\"\"\"\n",
    "model_vllm_config = yaml.safe_load(model_vllm_config_yaml)\n",
    "llm_model = LLM(**model_vllm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180706a5-c22c-4249-80c6-5523cb613290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.51it/s, est. speed input: 46.93 toks/s, output: 24.22 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded Interest: I’m drawn to storylines where characters deal with existential questions and explore the themes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Step 4: Generate Expanded Interests Using LLM Reasoning\n",
    "def expand_interest(user_reviews):\n",
    "    prompt = f\"Given the following book interests, suggest related book themes, specific genres, and example book titles: {user_reviews}\"\n",
    "    output = llm_model.generate([prompt])[0]  # Extract first response object\n",
    "    expanded_text = output.outputs[0].text if hasattr(output, \"outputs\") and output.outputs else str(output)\n",
    "    return expanded_text.strip()\n",
    "\n",
    "# Example user with past book reviews\n",
    "user_reviews = \"I love epic sci-fi novels with deep world-building.\"\n",
    "expanded_interest = expand_interest(user_reviews)\n",
    "print(\"Expanded Interest:\", expanded_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95ad0c4-42ce-4381-8eea-9c38ac84c719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\n",
      "Compiler status PASS\n",
      "Model successfully exported to bert_feature_dir\n"
     ]
    }
   ],
   "source": [
    "## Step 5: trace Bert for generating embeddings \n",
    "import torch\n",
    "import torch_neuronx\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "export_dir = \"bert_feature_dir\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()  \n",
    "\n",
    "# Create dummy inputs for tracing\n",
    "batch_size = 1\n",
    "sequence_length = 512\n",
    "dummy_inputs = (\n",
    "    torch.ones((batch_size, sequence_length), dtype=torch.long),  # input_ids\n",
    "    torch.ones((batch_size, sequence_length), dtype=torch.long)   # attention_mask\n",
    ")\n",
    "\n",
    "# Trace and compile the model for AWS Neuron\n",
    "traced_model = torch_neuronx.trace(model, dummy_inputs)\n",
    "traced_model.save(export_dir + \"/model.pt\")\n",
    "\n",
    "print(f\"Model successfully exported to {export_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9ce8b76-0d23-4fbb-b25d-25f01ce7f042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/neuronx_distributed/modules/moe/expert_mlps.py:11: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from neuronx_distributed.modules.moe.blockwise import (\n"
     ]
    }
   ],
   "source": [
    "from optimum.neuron import NeuronModelForFeatureExtraction\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#import os\n",
    "#os.environ[\"NEURON_RT_VISIBLE_CORES\"] = \"2-3\"\n",
    "\n",
    "# Load compiled model (assuming you used \"bert_feature_dir\")\n",
    "model_dir = \"bert_feature_dir\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "embedding_model = NeuronModelForFeatureExtraction.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2546062b-b32b-4273-ba28-1c9ecb72f0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Embedding Shape: (768,)\n",
      "Embedding Sample: [ 0.01468755 -0.1420664   0.31523687 -0.031531    0.23696186 -0.09850309\n",
      " -0.02450292  0.58309984 -0.08324284  0.02135697]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Compute BERT embeddings for a given text.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {key: val for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = embedding_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "sample_text = books_df[\"review/text\"].iloc[0]  # Get first review\n",
    "embedding = get_embedding(sample_text)\n",
    "print(\"Sample Embedding Shape:\", embedding.shape)\n",
    "print(\"Embedding Sample:\", embedding[:10])  # Print first 10 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ffc5837-b5aa-4a39-b6bf-948d2763dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df[\"embedding\"] = books_df[\"review/text\"].apply(lambda x: get_embedding(x).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cb1b774-e47b-4b18-af4e-e506306c27cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Id                           Title         User_id  \\\n",
      "0  1882931173  Its Only Art If Its Well Hung!   AVCGYZL8FQQTD   \n",
      "1  0826414346        Dr. Seuss: American Icon  A30TK6U7DNS82R   \n",
      "2  0826414346        Dr. Seuss: American Icon  A3UH4UZ4RSVO82   \n",
      "3  0826414346        Dr. Seuss: American Icon  A2MVUWT453QH61   \n",
      "4  0826414346        Dr. Seuss: American Icon  A22X4XUPKF66MR   \n",
      "\n",
      "  review/helpfulness  review/score  review/time  \\\n",
      "0                7/7           4.0    940636800   \n",
      "1              10/10           5.0   1095724800   \n",
      "2              10/11           5.0   1078790400   \n",
      "3                7/7           4.0   1090713600   \n",
      "4                3/3           4.0   1107993600   \n",
      "\n",
      "                                    review/summary  \\\n",
      "0           Nice collection of Julie Strain images   \n",
      "1                                Really Enjoyed It   \n",
      "2  Essential for every personal and Public Library   \n",
      "3  Phlip Nel gives silly Seuss a serious treatment   \n",
      "4                           Good academic overview   \n",
      "\n",
      "                                         review/text  \\\n",
      "0  This is only for Julie Strain fans. It's a col...   \n",
      "1  I don't care much for Dr. Seuss but after read...   \n",
      "2  If people become the books they read and if \"t...   \n",
      "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...   \n",
      "4  Philip Nel - Dr. Seuss: American IconThis is b...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [0.014687552116811275, -0.14206640422344208, 0...  \n",
      "1  [-0.30076777935028076, 0.22291958332061768, 0....  \n",
      "2  [-0.37572726607322693, 0.227650985121727, 0.28...  \n",
      "3  [-0.22336000204086304, 0.07131016999483109, 0....  \n",
      "4  [-0.22212007641792297, 0.17377790808677673, 0....  \n",
      "[0.014687552116811275, -0.14206640422344208, 0.3152368664741516, -0.03153100237250328, 0.23696185648441315, -0.09850309044122696, -0.024502919986844063, 0.5830998420715332, -0.08324284106492996, 0.021356971934437752]\n"
     ]
    }
   ],
   "source": [
    "print(books_df.head())\n",
    "print(books_df[\"embedding\"].iloc[0][:10])  # Print first 10 values of the first embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b565f6e-99f4-408a-95ee-8aec00632f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved.\n"
     ]
    }
   ],
   "source": [
    "## Step 6: Store and Retrieve Embeddings Using FAISS\n",
    "import faiss\n",
    "\n",
    "# Convert embeddings into numpy array\n",
    "embeddings_matrix = np.array(books_df[\"embedding\"].tolist()).astype(\"float32\")\n",
    "\n",
    "# Create FAISS index\n",
    "index = faiss.IndexFlatL2(768)  # 768 = embedding dimension from BERT\n",
    "index.add(embeddings_matrix)\n",
    "\n",
    "# Save index for reuse\n",
    "faiss.write_index(index, \"books_faiss_index.faiss\")\n",
    "print(\"FAISS index saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "630263b4-f2a3-4452-88cc-f1b992a0a843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s, est. speed input: 47.39 toks/s, output: 24.46 toks/s]\n",
      "Processed prompts: 100%|██████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s, est. speed input: 47.66 toks/s, output: 24.60 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded Interest: Every time I try to visualize a book's setting, I imagine it as a\n",
      "Recommended Books:\n",
      "                              Title  \\\n",
      "8117                     Foundation   \n",
      "9664                    Pushing Ice   \n",
      "2995  Space Stations and Graveyards   \n",
      "3600                         Island   \n",
      "3608                         Island   \n",
      "\n",
      "                                      review/summary  \n",
      "8117                      The Softest of Soft Sci Fi  \n",
      "9664                             Absolutely AWESOME!  \n",
      "2995  Good combination of science fiction and horror  \n",
      "3600                      Raises Some Good Questions  \n",
      "3608                      Raises Some Good Questions  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Step 7: Implement book recommendations \n",
    "def recommend_books(user_reviews, top_k=5):\n",
    "    # Generate expanded interest text\n",
    "    expanded_interest = expand_interest(user_reviews)  \n",
    "    \n",
    "    # Generate embedding for expanded interest\n",
    "    query_embedding = get_embedding(expanded_interest).astype(\"float32\").reshape(1, -1)\n",
    "    \n",
    "    # Search in FAISS index\n",
    "    distances, indices = index.search(query_embedding, top_k)\n",
    "\n",
    "    # Retrieve books from dataset\n",
    "    recommended_books = books_df.iloc[indices[0]]  # Fetch rows by index\n",
    "\n",
    "    return recommended_books\n",
    "\n",
    "\n",
    "# Example: Find books similar to an interest\n",
    "user_reviews = \"I love epic sci-fi novels with deep world-building.\"\n",
    "recommended_books = recommend_books(user_reviews)\n",
    "\n",
    "print(\"Expanded Interest:\", expand_interest(user_reviews))\n",
    "print(\"Recommended Books:\")\n",
    "print(recommended_books[[\"Title\", \"review/summary\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd062424-361c-41e9-953b-e57dedc3037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now that we checked how single expended interest works, lets precompute the embeddings for the entire dataset before \n",
    "## querying will significantly speed up the recommendation process and make the system more efficient. \n",
    "## Right now, recommend_books(user_reviews) computes everything on the fly, which is inefficient.\n",
    "import numpy as np\n",
    "\n",
    "# Compute embeddings for all book reviews in advance\n",
    "if \"embedding\" not in books_df.columns:\n",
    "    books_df[\"embedding\"] = books_df[\"review/text\"].apply(lambda x: get_embedding(x).tolist())\n",
    "\n",
    "# Convert to NumPy array (FAISS requires float32)\n",
    "book_embeddings = np.array(books_df[\"embedding\"].tolist()).astype(\"float32\")\n",
    "\n",
    "# Normalize embeddings for better FAISS search (optional but recommended)\n",
    "import faiss\n",
    "faiss.normalize_L2(book_embeddings)\n",
    "\n",
    "# Build FAISS index\n",
    "index = faiss.IndexFlatL2(book_embeddings.shape[1])  # L2 search index\n",
    "index.add(book_embeddings)  # Add precomputed embeddings to FAISS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46789a56-67d2-472c-b1a7-3b09a7358277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s, est. speed input: 47.51 toks/s, output: 24.52 toks/s]\n",
      "Processed prompts: 100%|██████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s, est. speed input: 47.59 toks/s, output: 24.56 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded Interest: I enjoy speculative fiction that feels realistic, where the story seamlessly integrates into the real\n",
      "Recommended Books:\n",
      "                                                  Title  \\\n",
      "434                  Night World: Daughters Of Darkness   \n",
      "6538  Tess of the D'Urbervilles: A pure woman (Harpe...   \n",
      "5740  Prodigal Son (Dean Koontz's Frankenstein, Book 1)   \n",
      "7912                                         Foundation   \n",
      "5811                          Night Visitor (Timeswept)   \n",
      "\n",
      "                          review/summary  \n",
      "434                  It's got me hooked.  \n",
      "6538             Tess ofthe d'Ubervilles  \n",
      "5740                            Gripping  \n",
      "7912       The greatest sci-fi book ever  \n",
      "5811  original and lush with description  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example user with past book reviews\n",
    "user_reviews = \"I love epic sci-fi novels with deep world-building.\"\n",
    "recommended_books = recommend_books(user_reviews)\n",
    "\n",
    "print(\"Expanded Interest:\", expand_interest(user_reviews))\n",
    "print(\"Recommended Books:\")\n",
    "print(recommended_books[[\"Title\", \"review/summary\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630dcbf3-68fb-466f-8732-4c81af2c67cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
