model: "meta-llama/Llama-3.2-1B"
tensor_parallel_size: 2
max_num_seqs: 1
max_model_len: 2048
override_neuron_config:
  skip_warmup: true
device: "neuron"
