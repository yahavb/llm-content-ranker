speculative_model: "yuhuili/EAGLE-LLaMA3.1-Instruct-8B"
speculative_draft_tensor_parallel_size: 1
speculative_max_model_len: 1024
num_speculative_tokens: 5
model: "meta-llama/Llama-3.1-8B-Instruct"
tensor_parallel_size: 8
max_num_seqs: 1
max_model_len: 1024
use_v2_block_manager: true
override_neuron_config: 
  enable_fused_speculation: true
  enable_eagle_speculation: true
  skip_warmup: true
device: "neuron"
